# 分布式事务层与共识层边界分析

## 文档概述

本文档详细分析了分布式事务层（Percolator事务模型）和分布式共识层（Raft算法）在JadeDB架构中的职责边界、交互方式和设计原则。理解这两层的区别对于正确实现分布式数据库至关重要。

## 核心概念对比

### 分布式事务层 (Percolator)
- **职责**：保证跨多个数据分片的事务ACID特性
- **范围**：应用层的事务语义，用户可见的事务边界
- **一致性**：快照隔离（Snapshot Isolation）
- **时间维度**：基于全局时间戳的多版本并发控制

### 分布式共识层 (Raft)  
- **职责**：保证单个数据分片内部的强一致性
- **范围**：系统层的数据复制，用户不可见的内部机制
- **一致性**：线性一致性（Linearizability）
- **时间维度**：基于日志序列的状态机复制

---

## 职责边界详细分析

### 1. Percolator事务层职责

```go
// Percolator事务管理器 - 处理跨分片事务
type PercolatorTxnManager struct {
    // 全局时间戳服务
    tsoService *TSOService
    
    // 事务协调器 - 管理分布式事务
    coordinator *TransactionCoordinator
    
    // 锁管理器 - 管理分布式锁
    lockManager *PercolatorLockManager
    
    // MVCC管理器 - 多版本并发控制
    mvccManager *PercolatorMVCCManager
}

// 核心职责：
// 1. 跨分片事务协调：协调涉及多个数据分片的事务
// 2. 全局时间戳管理：为所有事务分配全局唯一的时间戳
// 3. 分布式锁管理：管理跨分片的Primary/Secondary锁
// 4. 冲突检测：检测跨事务的读写冲突
// 5. 两阶段提交：确保分布式事务的原子性
```

**关键特点**：
- **用户可见**：用户通过BEGIN/COMMIT操作直接与事务层交互
- **跨分片协调**：一个事务可能涉及多个数据分片
- **时间戳驱动**：基于全局时间戳实现快照隔离
- **最终一致性**：在网络分区时可能出现暂时不一致

### 2. Raft共识层职责

```go
// Raft节点 - 处理单分片内的一致性
type RaftNode struct {
    // 节点状态
    state RaftState // Leader/Follower/Candidate
    
    // 日志复制
    log *RaftLog
    
    // 状态机
    stateMachine StateMachine
    
    // 集群成员
    peers map[string]*RaftPeer
}

// 核心职责：
// 1. 领导者选举：在分片内选举唯一的领导者
// 2. 日志复制：将操作日志复制到所有副本
// 3. 状态机应用：确保所有副本以相同顺序应用操作
// 4. 成员管理：处理节点加入/离开
// 5. 故障检测：检测和处理节点故障
```

**关键特点**：
- **用户不可见**：用户无法直接感知Raft的存在
- **分片内一致性**：只保证单个分片内的强一致性
- **日志驱动**：基于日志序列号实现线性一致性
- **强一致性**：在任何时刻都保证数据一致性

---

## 交互方式和边界

### 1. 层次关系

```
┌─────────────────────────────────────────────────────────┐
│                SQL执行引擎                                │
└─────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────┐
│              Percolator事务层                            │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐      │
│  │   TSO服务   │  │  事务协调器  │  │  锁管理器   │      │
│  └─────────────┘  └─────────────┘  └─────────────┘      │
└─────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────┐
│                 Raft共识层                               │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐      │
│  │  Raft节点1  │  │  Raft节点2  │  │  Raft节点3  │      │
│  └─────────────┘  └─────────────┘  └─────────────┘      │
└─────────────────────────────────────────────────────────┘
                            │
                            ▼
┌─────────────────────────────────────────────────────────┐
│                存储引擎层                                │
│  ┌─────────────┐              ┌─────────────┐           │
│  │  LSM引擎    │              │  B+树引擎   │           │
│  └─────────────┘              └─────────────┘           │
└─────────────────────────────────────────────────────────┘
```

### 2. 具体交互场景

#### 场景1：单分片事务
```go
// 1. 用户发起事务
BEGIN;
UPDATE table1 SET value = 'new' WHERE id = 1;
COMMIT;

// 2. Percolator事务层处理
func (ptm *PercolatorTxnManager) ExecuteUpdate(sql string) error {
    // 2.1 获取全局时间戳
    startTS := ptm.tsoService.GetTimestamp()
    
    // 2.2 确定数据分片（假设在分片A）
    shard := ptm.getShardForKey("table1:id:1")
    
    // 2.3 向Raft层提交操作
    operation := &Operation{
        Type: "PREWRITE",
        Key:  "table1:id:1", 
        Value: "new",
        StartTS: startTS,
    }
    
    // 通过Raft确保操作的一致性复制
    return shard.raftNode.Propose(operation)
}

// 3. Raft共识层处理
func (rn *RaftNode) Propose(data []byte) error {
    // 3.1 只有Leader可以接受提议
    if rn.state != Leader {
        return ErrNotLeader
    }
    
    // 3.2 添加到日志
    entry := LogEntry{
        Term: rn.currentTerm,
        Index: rn.log.getLastIndex() + 1,
        Data: data,
    }
    rn.log.append(entry)
    
    // 3.3 复制到所有Follower
    rn.replicateToFollowers(entry)
    
    // 3.4 应用到状态机
    rn.stateMachine.Apply(entry)
    
    return nil
}
```

#### 场景2：跨分片事务
```go
// 1. 用户发起跨分片事务
BEGIN;
UPDATE table1 SET value = 'new1' WHERE id = 1; // 分片A
UPDATE table2 SET value = 'new2' WHERE id = 2; // 分片B  
COMMIT;

// 2. Percolator事务层协调
func (ptm *PercolatorTxnManager) ExecuteDistributedTxn(operations []Operation) error {
    startTS := ptm.tsoService.GetTimestamp()
    
    // 2.1 选择Primary Key（第一个操作的key）
    primaryKey := operations[0].Key
    primaryShard := ptm.getShardForKey(primaryKey)
    
    // 2.2 Phase 1: Prewrite所有分片
    for _, op := range operations {
        shard := ptm.getShardForKey(op.Key)
        
        prewriteOp := &Operation{
            Type: "PREWRITE",
            Key: op.Key,
            Value: op.Value,
            StartTS: startTS,
            PrimaryKey: primaryKey, // 指向Primary Key
        }
        
        // 每个分片内部通过Raft保证一致性
        if err := shard.raftNode.Propose(prewriteOp); err != nil {
            return err
        }
    }
    
    // 2.3 Phase 2: Commit Primary Key
    commitTS := ptm.tsoService.GetTimestamp()
    commitOp := &Operation{
        Type: "COMMIT",
        Key: primaryKey,
        StartTS: startTS,
        CommitTS: commitTS,
    }
    
    // Primary分片提交
    if err := primaryShard.raftNode.Propose(commitOp); err != nil {
        return err
    }
    
    // 2.4 异步提交Secondary Keys
    go ptm.commitSecondaryKeys(operations[1:], startTS, commitTS)
    
    return nil
}
```

---

## 关键设计原则

### 1. 职责分离原则

**Percolator层关注**：
- ✅ 事务的业务语义（ACID特性）
- ✅ 跨分片的数据一致性
- ✅ 用户可见的事务边界
- ✅ 全局时间戳和版本管理

**Raft层关注**：
- ✅ 单分片内的数据复制
- ✅ 节点故障和网络分区处理
- ✅ 日志的顺序和持久化
- ✅ 集群成员管理

### 2. 抽象层次原则

```go
// 错误的设计：Percolator直接操作存储引擎
func (ptm *PercolatorTxnManager) BadDesign() {
    // ❌ 绕过了Raft层，破坏了一致性保证
    ptm.storageEngine.Put(key, value)
}

// 正确的设计：Percolator通过Raft操作数据
func (ptm *PercolatorTxnManager) GoodDesign() {
    // ✅ 通过Raft确保操作的一致性复制
    operation := &Operation{Type: "PUT", Key: key, Value: value}
    ptm.raftNode.Propose(operation)
}
```

### 3. 一致性保证原则

**Percolator保证**：
- 快照隔离：事务看到一致的数据快照
- 原子性：分布式事务要么全部成功要么全部失败
- 持久性：已提交的事务不会丢失

**Raft保证**：
- 线性一致性：所有操作有全局顺序
- 持久性：已提交的日志不会丢失
- 可用性：只要大多数节点存活就可以服务

---

## 实际应用场景

### TiDB中的实现

在TiDB中，这两层的边界非常清晰：

1. **TiDB Server（事务层）**：
   - 处理SQL解析和优化
   - 管理分布式事务（Percolator模型）
   - 与PD交互获取时间戳

2. **TiKV（共识层）**：
   - 每个Region使用Raft保证一致性
   - 处理数据的读写和复制
   - 管理Region的分裂和合并

### JadeDB中的设计

基于这个分析，JadeDB的架构应该是：

```go
// JadeDB分布式架构
type JadeDBCluster struct {
    // SQL层
    sqlEngine *SQLEngine
    
    // 事务层（Percolator）
    txnManager *PercolatorTxnManager
    
    // 共识层（Raft）
    shards map[string]*RaftShard
    
    // 存储层
    storageEngines map[string]storage.Engine
}

type RaftShard struct {
    shardID   string
    raftNode  *RaftNode
    engine    storage.Engine // LSM或B+树
}
```

这样的设计确保了：
- **清晰的职责边界**：每层只关注自己的职责
- **正确的抽象层次**：上层通过下层的接口操作
- **一致性保证**：每层提供自己的一致性语义
- **可扩展性**：可以独立扩展每一层的功能

理解这个边界对于正确实现分布式数据库至关重要，它决定了系统的架构清晰度和可维护性。
